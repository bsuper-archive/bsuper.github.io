<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>blog.bsu.me/</title>
   
   <link>http://blog.bsu.me/</link>
   <description>A place where I'll share my latest travel stories, academic thoughts, and personal musings.</description>
   <language>en-us</language>
   <managingEditor> Brian Su</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Prioritized Experience Replay Kills on Doom</title>
	  <link>//294-dqn-doom</link>
	  <author>Brian Su</author>
	  <pubDate>2016-12-06T00:00:00+00:00</pubDate>
	  <guid>//294-dqn-doom</guid>
	  <description><![CDATA[
	     <h3>Why play video games?</h3>
<p>
  You may wonder why companies like Google and Facebook have research teams that try to outperform others (and themselves) on video games, such as Atari or Doom. I mean, why would some of the best minds of our day spend hours tackling how to be better at video games?
</p>
<p>
  Turns out, the eventual goal is to use reinforcement learning to allow robots and other machines to interact with complex environments. In short, games are a simplified abstraction of a complex environment machines have to learn and adapt to. Once we have successfully trained a model to play a game, applying the model to a real-world problem is a natural extension. For example, Google’s DeepMind has trained reinforcement learning models to master Atari games, beat a 9-dan Go professional, and, more recently, reduced the power consumption of Google’s data centers by 15%. Moreover,  games provide two advantages when used for deep reinforcement learning.
</p>
<p>
  First, since machines can quickly run through games, we are able to accumulate much more data from playing games compared to attempting to collect data in the real-world. In particular, this is beneficial when using deep neural networks they require lots of data to be able to perform successfully.
</p>
<p>
  Second, games provide a visual representation of an environment. When humans play games, they learn how to play and make decisions based on what they see on the screen. Cameras are machines’ equivalent of human eyes, capturing a representation of the environment as an image, and machine learning has been successfully done to detect objects in the images. Thus, for humans and these machine learning models, the input is the raw pixels from images. For the task of deep reinforcement learning, most games provide a visual representation capturing most of the state of the game. Like how humans learn to play games, the goal is to use deep reinforcement learning and allow machines only use the visual representation to successfully complete the game. This is often referred to as end-to-end training.
</p>
<p>
  CAD2RL is one recent example where researchers, using deep reinforcement learning, trained a drone to navigate through corridors using only simulation images and achieved decent success on flying through the hallways of Cory Hall. By using simulation images, the authors exposed the drone to many complex environments and were able to “reset” the environment when the drone crashed in simulation without any damage to the drone in real life.
</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/nXBWmzFrj5s" frameborder="0" allowfullscreen></iframe>

	  ]]></description>
	</item>


</channel>
</rss>
